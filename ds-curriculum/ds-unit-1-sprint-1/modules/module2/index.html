<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Module 2: Exploratory Data Analysis & Feature Engineering - Data Science Sprint 1</title>
    <link rel="stylesheet" href="../../../css/style.css">
</head>

<body>
    <header>
        <nav>
            <div class="logo">Data Science Unit 1</div>
            <ul>
                <li><a href="../../index.html">Home</a></li>
                <li class="dropdown">
                    <a href="#" class="active">Modules</a>
                    <div class="dropdown-content">
                        <a href="../module1/index.html">Module 1: Python Fundamentals</a>
                        <a href="../module2/index.html" class="active">Module 2: Exploratory Data Analysis & Feature
                            Engineering</a>
                        <a href="../module3/index.html">Module 3: Join and Reshape Data</a>
                        <a href="../module4/index.html">Module 4: Make Explanatory Visualizations</a>
                    </div>
                </li>
                <li><a href="../../code-alongs/index.html">Code-Alongs</a></li>
                <li><a href="../../sprint-challenge/index.html">Sprint Challenge</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <h1>Module 2: Exploratory Data Analysis & Feature Engineering</h1>

        <section class="content-box">
            <h2>Module Overview</h2>
            <p>In this module, you'll learn how to work with data using Google Colab and Pandas. You'll discover how to
                read and load datasets, explore your data using Pandas' powerful analysis tools, perform feature
                engineering to transform your data, and master string functions in Pandas for text data manipulation.
            </p>
        </section>

        <section class="content-box">
            <h2>Learning Objectives</h2>
            <ul>
                <li>Read and load datasets using Google Colab and Pandas</li>
                <li>Explore and analyze data using Pandas' functionality</li>
                <li>Apply feature engineering techniques to transform and prepare data</li>
                <li>Master string functions in Pandas for text data manipulation</li>
            </ul>
        </section>

        <!-- Detailed Objectives -->
        <section class="content-box">
            <h2>Detailed Objective: Exploratory Data Analysis (EDA)</h2>
            <p>Exploratory data analysis (EDA) is an essential part of learning to be a data scientist. And something
                that experienced data scientists do regularly.</p>
            <p>We'll be using some of the numerous tools available in the pandas library. Earlier in the module, we
                learned how to load datasets into notebooks. So now that we have all this data, what do we do with it?
            </p>

            <h3>Basic Information Methods</h3>
            <p>We can use a few methods to quickly look at your DataFrame and get an idea of what's inside. Here are
                some of the most common descriptions of what each method does:</p>

            <div class="table-responsive">
                <table class="table">
                    <thead>
                        <tr>
                            <th><strong>Method</strong></th>
                            <th><strong>Description</strong></th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>df.shape</code></td>
                            <td>Display the size (rows, columns)</td>
                        </tr>
                        <tr>
                            <td><code>df.head()</code></td>
                            <td>Display the first 5 rows (we can display first n rows by including the number in
                                parenthesis)</td>
                        </tr>
                        <tr>
                            <td><code>df.tail()</code></td>
                            <td>Display the last 5 rows (we can display last n rows by including the number in
                                parenthesis)</td>
                        </tr>
                        <tr>
                            <td><code>df.describe()</code></td>
                            <td>Display the statistics of numerical data types</td>
                        </tr>
                        <tr>
                            <td><code>df.info()</code></td>
                            <td>Display the number of entries (rows), number of columns, and the data types</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>Column-specific Methods</h3>
            <p>Sometimes we don't want to look at the entire DataFrame and instead focus on a single column or a few
                columns. There are a few ways to select a column, but we'll mainly use the column name. For example, if
                we have a DataFrame called <code>df</code> and a column named "column_1," we could select just a single
                column by using <code>df["column_1"]</code>. Once we have a single column chosen, we can use some of the
                following methods to get more information.</p>

            <div class="table-responsive">
                <table class="table">
                    <thead>
                        <tr>
                            <th><strong>Method</strong></th>
                            <th><strong>Description</strong></th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>df.columns</code></td>
                            <td>Print a list of the columns</td>
                        </tr>
                        <tr>
                            <td><code>df['column_name']</code></td>
                            <td>Select a single column (returns a Series)</td>
                        </tr>
                        <tr>
                            <td><code>df['column_name'].value_counts()</code></td>
                            <td>Count the number of <code>object</code> and <code>boolean</code> occurrences</td>
                        </tr>
                        <tr>
                            <td><code>df.sort_values(by='column_name')</code></td>
                            <td>Sort the values in the given column</td>
                        </tr>
                        <tr>
                            <td><code>df.drop()</code></td>
                            <td>Remove rows or columns by specifying the label or index of the row/column</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>Handling Missing Values</h3>
            <p>With a lot of data comes the unavoidable fact that some of it will be messy. Messy data means that there
                will be missing values, "not-a-number" (NaN) occurrences, and problems with zeros not being zero.
                Fortunately, several pandas methods make dealing with the mess a little easier.</p>

            <div class="table-responsive">
                <table class="table">
                    <thead>
                        <tr>
                            <th><strong>Method</strong></th>
                            <th><strong>Description</strong></th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>df.isnull().sum()</code></td>
                            <td>Count and sum the number of null occurrences (NaN or None)</td>
                        </tr>
                        <tr>
                            <td><code>df.fillna()</code></td>
                            <td>Fill NaN values in a variety of ways</td>
                        </tr>
                        <tr>
                            <td><code>df.dropna()</code></td>
                            <td>Remove values that are NaN or None; by default removes all rows with NaNs</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <h3>Practical Example</h3>
            <p>Let's see a practical example of EDA using the M&Ms dataset, which is small and contains both numeric and
                object (string) data types:</p>

            <div class="code-example">
                <pre><code class="language-python"># Import pandas
import pandas as pd

# Read the data from the website
url_mms = 'https://tinyurl.com/mms-statistics'
df = pd.<code>read_csv</code>(url_mms)

# Look at the shape
df.shape  # returns (816, 4)

# Look at the head of the file
df.head()</code></pre>
            </div>

            <p>When we run <code>df.head()</code>, we'll see the first 5 rows of the dataset with columns 'type',
                'color', 'diameter', and 'mass'. We can get more information about the dataset with:</p>

            <div class="code-example">
                <pre><code class="language-python"># DataFrame information
df.info()</code></pre>
            </div>

            <p>The output will tell us we have 816 entries, 4 columns, and reveal the data types. Let's also check the
                statistics of the numeric columns:</p>

            <div class="code-example">
                <pre><code class="language-python"># DataFrame describe
df.describe()</code></pre>
            </div>

            <p>This shows statistics like count, mean, standard deviation, min/max, and percentiles for numeric columns.
            </p>

            <p>What if we want to count how many of each candy type we have?</p>
        </section>

        <section class="content-box">
            <h2>Objective 01 - Load a CSV Dataset From a URL Using Pandas <code>read_csv</code></h2>
            <h3>Overview</h3>
            <p>
                We will be working with data in many different forms throughout this course. But before we can start to
                do anything with that data, we need to load it into our workspace. So we'll be working in Google Colab
                notebooks, focusing on loading data into that environment. Eventually, you'll be working with a local
                Jupyter environment, but these instructions will work for that, too.
            </p>
            <h3>Pandas</h3>
            <p>
                You are likely already familiar with the Python data analysis library pandas. We'll provide a quick
                overview here and then work through some examples in the next section.
            </p>
            <p>
                The pandas library provides extensive data analysis and data manipulation tools. It also includes data
                structures (Series, DataFrames) that work well with various data types, including tabular data,
                time-series data, and arbitrary matrix data (for example, columns with different data types).
            </p>
            <h3>Reading files using <code></code>read.csv</code></h3>
            <p>
                To start, we'll learn how to load data with one of the most common pandas methods:
                <code>read_csv</code>. This method
                reads data in the comma-separated value or CSV format: the values in each row are separated by a comma,
                and new lines (rows) begin on the following line. A CSV file can be read from a locally saved file on
                your computer or loaded from a URL. We'll practice both these techniques in this module, starting with
                data that is stored online.
            </p>
            <p>
                As with many pandas methods, there are several options to use with <code>read_csv</code>. To learn about
                these, an
                excellent place to begin is with some of the <a
                    href="https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html#user-guide" target="_blank"
                    rel="noopener noreferrer">official documentation</a>.
            </p>
            <p>
                For this first exercise, we will use the default <code>read_csv</code> parameters. Time to read in some
                data!
            </p>
            <h3>Follow Along</h3>
            <p>
                We will practice using the <code>read_csv</code> method to load a data set from a URL. The <a
                    href="https://archive.ics.uci.edu/" target="_blank" rel="noopener noreferrer">UCI Machine
                    Learning Repository</a> has a great selection of data sets, and many are in a good format for
                practicing.
            </p>
            <p>
                The <a href="https://archive.ics.uci.edu/dataset/101/tic+tac+toe+endgame" target="_blank"
                    rel="noopener noreferrer">Tic-Tac-Toe Endgame</a> data set is a manageable size (~900 rows) and has
                ten columns; this size makes it easy to examine once we read it in. To retrieve the URL, click on the
                above link and click on the <strong>Download: Data Folder</strong> link. You should see a list;
                right-click on <strong>tic-tac-toe data</strong> and select <strong>Copy link address.</strong>
            </p>
            <p>
                In your notebook, you can use the following code to read in the data set:
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Import pandas with the standard alias
import pandas as pd

# Set a variable to the URL you copied above
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/tic-tac-toe/tic-tac-toe.data'

# Read or load the data
df = pd.<code>read_csv</code>(url)
</code></pre>
            </div>
            <p>
                Great! If you copied the link correctly, you should have sucessfully loaded the data set. A simple check
                is to type the variable name and run the cell:
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Look at the data (df)
df.head()
</code></pre>
            </div>
            <div class="table-responsive">
                <table class="custom-table">
                    <thead>
                        <tr>
                            <th></th>
                            <th>x</th>
                            <th>x.1</th>
                            <th>x.2</th>
                            <th>x.3</th>
                            <th>o</th>
                            <th>o.1</th>
                            <th>x.4</th>
                            <th>o.2</th>
                            <th>o.3</th>
                            <th>positive</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>0</td>
                            <td>x</td>
                            <td>x</td>
                            <td>x</td>
                            <td>x</td>
                            <td>o</td>
                            <td>o</td>
                            <td>o</td>
                            <td>x</td>
                            <td>o</td>
                            <td>positive</td>
                        </tr>
                        <tr>
                            <td>1</td>
                            <td>x</td>
                            <td>x</td>
                            <td>x</td>
                            <td>x</td>
                            <td>o</td>
                            <td>o</td>
                            <td>o</td>
                            <td>o</td>
                            <td>x</td>
                            <td>positive</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>x</td>
                            <td>x</td>
                            <td>x</td>
                            <td>x</td>
                            <td>o</td>
                            <td>o</td>
                            <td>o</td>
                            <td>b</td>
                            <td>b</td>
                            <td>positive</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>x</td>
                            <td>x</td>
                            <td>x</td>
                            <td>x</td>
                            <td>o</td>
                            <td>o</td>
                            <td>b</td>
                            <td>o</td>
                            <td>b</td>
                            <td>positive</td>
                        </tr>
                        <tr>
                            <td>x</td>
                            <td>x</td>
                            <td>x</td>
                            <td>x</td>
                            <td>o</td>
                            <td>o</td>
                            <td>b</td>
                            <td>b</td>
                            <td>o</td>
                            <td>positive</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <p>
                We can see that there isn't a header row (a row with labels for each column). To fix this, look up the
                information for this data set, and manually create a list of columns names; this list could be set as
                the header row.
            </p>
            <h3>Challenge</h3>
            <p>
                Since the data set we read above is missing a header row, this would be an excellent time to practice
                adding one. For the UCI Repository specifically, the information about the data sets is often located in
                the same “Data Folder” from where you downloaded it.
            </p>
            <p>
                Here are some steps to get started:
            </p>
            <ul>
                <li>Navigate to the "Data Folder" and look for a file that ends in .names; view the file (download and
                    open if needed) and learn what each column represents</li>
                <li>Create a Python list with column names; example: <code>mycols = ['col 1', 'col 2', 'col 3']</code>
                    (make sure the
                    number of column names in your lists matches the number of columns in your data set)</li>
                <li>Try this option first: <code>df = pd.<code>read_csv</code>(url, header=None)</code></li>
                <li>And compare to this option: <code>df = pd.<code>read_csv</code>(url, header=1)</code></li>
                <li>Using the column names you set above, try this option:
                    <code>df = pd.<code>read_csv</code>(url, names=mycols)</code>
                </li>
            </ul>
            <h3>Additional Resources</h3>
            <ul>
                <li><a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-read-csv-table"
                        target="_blank" rel="noopener noreferrer">Pandas documentation: CSV &amp; text files</a></li>
                <li><a href="https://archive.ics.uci.edu/" target="_blank" rel="noopener noreferrer">UCI Machine
                        Learning Repository</a></li>
            </ul>
        </section>

        <section class="content-box">
            <h2>Objective 02- Load a CSV dataset from a local file using Pandas <code>read_csv</code></h2>
            <h3>Overview</h3>
            <p>
                When working with data sets, you'll find many of them conveniently stored online at various locations
                (UCI Repository, Kaggle, etc.). But you'll often want to download a data set to store it on your local
                computer. Storing the data set makes it easy to use tools on your computer to view and edit the file, in
                addition to having a copy stored on your hard drive.
            </p>
            <p>
                The pandas <code>read_csv()</code> method can also read in locally saved files. Instead of providing the
                URL, you will use the path to the file. Think of the path like the address of the file: it's a list of
                directories leading to the file location. An example path might look like
                <code>/Users/myname/Documents/data_science/tic-tac-toe.data</code> where the last part of the path is
                the file name. To read in a local file with pandas, you can use the following code (assuming pandas has
                been installed on your computer):
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Read in an example file (from a example user's Downloads folder)
import pandas as pd
df = pd.read_csv('/home/username/Downloads/tic-tac-toe.data')</code></pre>
            </div>
            <p>
                Done! Common issues here are having an incorrect path listed for the file or an incorrect file name. You
                also need to make sure you include quotes (either single or double) around your path.
            </p>
            <p>
                Since we are currently working in notebooks on Google Colab, we need to know how to get data loaded into
                that environment.
            </p>
            <h3>Google Colab</h3>
            <p>
                There are a few different ways to load files into your Colab notebook. The first one we will cover here
                is loading a file from your computer. You need to have already downloaded and saved the file. The next
                step is to use the files method from the <code>google.colab</code> package:
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Upload a file to Colab from your computer
from google.colab import files
uploaded = files.upload()</code></pre>
            </div>
            <p>
                The system will prompt you to select a file.
            </p>
            <p>
                Select the <code>tic-tac-toe.data</code> file you downloaded. It should be in your Downloads folder.
            </p>
            <p>
                This should return a result that looks like this:
            </p>
            <div>
                <img id="634179" src="../../assets/DS_Sp_1_Obj_2_1.png" alt="Upload a file from Colab to your computer"
                    loading="lazy">
            </div>
            <p>
                Now, we can read our file into a DataFrame:
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Store your uploaded file in a pandas DataFrame 
df = pd.read_csv('tic-tac-toe.data')</code></pre>
            </div>
            <h3>Follow Along</h3>
            <p>
                Let's work through another example, where we read in a file from a notebook running locally and from a
                notebook running in Colab. We'll download another file from the UCI Machine Learning Repository: the <a
                    href="https://archive.ics.uci.edu/ml/datasets/auto+mpg" target="_blank"
                    rel="noopener noreferrer">Auto
                    MPG Data Set</a>.
            </p>
            <h4>Local Jupyter Notebook</h4>
            <p>
                If you are following along on your notebook running locally (on your computer, not on Google Colab),
                change the path to correspond to where you have saved the file on your computer.
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Load a file saved LOCALLY
import pandas as pd
df = pd.read_csv('/home/username/Downloads/auto-mpg.data')</code></pre>
            </div>
            <h4>Google Colab notebook</h4>
            <p>
                Now in a Colab notebook, we'll follow the same steps from the Overview and load this new data set and
                read it into a DataFrame:
            </p>
            <div class="code-example">
                <pre><code class="language-python">from google.colab import files
uploaded = files.upload()

# A prompt will ask you to choose a file
# Choose a file

# Store your uploaded file in a pandas DataFrame
import io
df = pd.read_csv(io.BytesIO(uploaded['auto-mpg.data']))</code></pre>
            </div>
            <p>
                In this case, we used the Python package <code>io</code>, which stands for input/output. The
                <code>io.BytesIO</code> is reading data stored as bytes in an in-memory buffer (in this case in Colab).
            </p>
            <p>
                You now have a new data set to explore!
            </p>
            <h3>Challenge</h3>
            <p>
                For more practice, look through the <a href="https://archive.ics.uci.edu/datasets" target="_blank"
                    rel="noopener noreferrer">UCI Machine Learning Repository</a> and find a data set to
                download to your computer. Make sure it is a CSV file and not in a different format. Upload into Google
                Colab and then load that file into a DataFrame.
            </p>
            <h3>Additional Resources</h3>
            <ul>
                <li><a href="https://colab.research.google.com/notebooks/io.ipynb" target="_blank"
                        rel="noopener noreferrer">Google Colab - External data: Local Files, Drive, Sheets, and Cloud
                        Storage</a></li>
                <li><a href="https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92"
                        target="_blank" rel="noopener noreferrer">Three ways to load CSV into Colab</a></li>
            </ul>
        </section>

        <section class="content-box">
            <h2>Objective 03 - Use Basic Pandas Functions for Exploratory Data Analysis-EDA Overview</h2>
            <h3>Overview</h3>
            <p>
                Exploratory data analysis (EDA) is an essential part of learning to be a data scientist. And something
                that experienced data scientists do regularly.
            </p>
            <p>
                We'll be using some of the numerous tools available in the pandas library. Earlier in the module, we
                learned how to load datasets into notebooks. So now that we have all this data, what do we do with it?
            </p>
            <h3>Basic Information</h3>
            <p>
                We can use a few methods to look at your DataFrame quickly and get an idea of what's inside. Here are
                some of the most common descriptions of what each method does:
            </p>
            <div class="table-responsive">
                <table class="table">
                    <thead>
                        <tr>
                            <th>method</th>
                            <th>description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>df.shape</code></td>
                            <td>display the size (x, y)</td>
                        </tr>
                        <tr>
                            <td><code>df.head()</code></td>
                            <td>display the first 5 rows ( we can display first n rows by including the number in
                                parenthesis)</td>
                        </tr>
                        <tr>
                            <td><code>df.tail()</code></td>
                            <td>display the last 5 rows ( we can display last n rows by including the number in
                                parenthesis)</td>
                        </tr>
                        <tr>
                            <td><code>df.describe()</code></td>
                            <td>display the statistics of numerical data types</td>
                        </tr>
                        <tr>
                            <td><code>df.info()</code></td>
                            <td>display the number of entries (rows), number of columns, and the data types</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <h3>Column-specific</h3>
            <p>
                Sometimes we don't want to look at the entire DataFrame and instead focus on a single column or a few
                columns. There are a few ways to select a column, but we'll mainly use the column name. For example, if
                we have a DataFrame called <code>df</code> and a column named “column_1,” we could select just a single
                column by using <code>df["column_1"]</code>. Once we have a single column chosen, we can use some of the
                following methods to get more information.
            </p>
            <div class="table-responsive">
                <table class="table">
                    <thead>
                        <tr>
                            <th>method</th>
                            <th>description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>df.columns</code></td>
                            <td>print a list of the columns</td>
                        </tr>
                        <tr>
                            <td><code>df['column_name']</code></td>
                            <td>select a single column ( returns a Series)</td>
                        </tr>
                        <tr>
                            <td><code>df['column_name'].value_counts()</code></td>
                            <td>count the number of object and boolean occurrences</td>
                        </tr>
                        <tr>
                            <td><code>df.sort_values(by='column_name')</code></td>
                            <td>sort the values in the given column</td>
                        </tr>
                        <tr>
                            <td><code>df.drop()</code></td>
                            <td>remove rows or columns by specifying the label or index of the row/column</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <h3>Missing Values</h3>
            <p>
                With a lot of data comes the unavoidable fact that some of it will be messy. Messy data means that there
                will be missing values, “not-a-number” (NaN) occurrences, and problems with zeros not being zero.
                Fortunately, several pandas methods make dealing with the mess a little easier.
            </p>
            <div class="table-responsive">
                <table class="table">
                    <thead>
                        <tr>
                            <th>method</th>
                            <th>description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>df.isnull().sum()</code></td>
                            <td>count and sum the number of null occurrences (NaN or None)</td>
                        </tr>
                        <tr>
                            <td><code>df.fillna()</code></td>
                            <td>fill NaN values in a variety of ways</td>
                        </tr>
                        <tr>
                            <td><code>df.dropna()</code></td>
                            <td>remove values that are NaN or None; by default removes all rows with NaNs</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <h3>Follow Along</h3>
            <p>
                The above methods cover much ground, but we'll work through examples using them on a data set. But,
                first, we need some data. We'll use the M&Ms data set for this because it's small and contains both
                numeric and Object (string) data types.
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Import pandas
import pandas as pd

# Read the data from the website
url_mms = 'https://tinyurl.com/mms-statistics'
df = pd.read_csv(url_mms)

# Look at the shape
df.shape  # returns (816, 4)

# Look at the head of the file
df.head()</code></pre>
            </div>
            <div class="table-responsive">
                <table class="custom-table">
                    <thead>
                        <tr>
                            <th> </th>
                            <th>type</th>
                            <th>color</th>
                            <th>diameter</th>
                            <th>mass</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>0</td>
                            <td>peanut butter</td>
                            <td>blue</td>
                            <td>16.20</td>
                            <td>2.18</td>
                        </tr>
                        <tr>
                            <td>1</td>
                            <td>peanut butter</td>
                            <td>brown</td>
                            <td>16.50</td>
                            <td>2.01</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>peanut butter</td>
                            <td>orange</td>
                            <td>15.48</td>
                            <td>1.78</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>peanut butter</td>
                            <td>brown</td>
                            <td>16.32</td>
                            <td>1.98</td>
                        </tr>
                        <tr>
                            <td>4</td>
                            <td>peanut butter</td>
                            <td>yellow</td>
                            <td>15.59</td>
                            <td>1.62</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <p>
                Let's look at the information using <code>df.info()</code>:
            </p>
            <div class="code-example">
                <pre><code class="language-python"># DataFrame information
df.info()</code></pre>
            </div>
            <pre>
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 816 entries, 0 to 815
Data columns (total 4 columns):
type        816 non-null object
color       816 non-null object
diameter    816 non-null float64
mass        816 non-null float64
dtypes: float64(2), object(2)
memory usage: 25.6+ KB
            </pre>
            <p>
                From this, we can see the columns “type” and “color” are object data types, and “diameter” and “mass”
                are numeric. We can use describe to print out the statistics for the numeric columns using
                <code>df.describe()</code>:
            </p>
            <div class="code-example">
                <pre><code class="language-python"># DataFrame describe
df.describe()</code></pre>
            </div>
            <div class="table-responsive">
                <table class="custom-table">
                    <thead>
                        <tr>
                            <th></th>
                            <th>diameter</th>
                            <th>mass</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>count</td>
                            <td>816.000000</td>
                            <td>816.000000</td>
                        </tr>
                        <tr>
                            <td>mean</td>
                            <td>14.171912</td>
                            <td>1.419632</td>
                        </tr>
                        <tr>
                            <td>std</td>
                            <td>1.220001</td>
                            <td>0.714765</td>
                        </tr>
                        <tr>
                            <td>min</td>
                            <td>11.230000</td>
                            <td>0.720000</td>
                        </tr>
                        <tr>
                            <td>25%</td>
                            <td>13.220000</td>
                            <td>0.860000</td>
                        </tr>
                        <tr>
                            <td>50%</td>
                            <td>13.600000</td>
                            <td>0.920000</td>
                        </tr>
                        <tr>
                            <td>75%</td>
                            <td>15.300000</td>
                            <td>1.930000</td>
                        </tr>
                        <tr>
                            <td>max</td>
                            <td>17.880000</td>
                            <td>3.620000</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <h3>DataFrame Columns</h3>
            <p>
                We can print out the columns of this data set with <code>df.columns</code> which returns an Index:
            </p>
            <div class="code-example">
                <pre><code class="language-python"># DataFrame columns
df.columns</code></pre>
            </div>
            <pre><code class="language-python">Index(['type', 'color', 'diameter', 'mass'], dtype='object')</code></pre>
            <p>
                To drop one of the columns, for example "mass", we'll use the <code>df.drop()</code> with the column
                specified:
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Drop the mass column
df.drop(columns='mass').head()</code></pre>
            </div>
            <div class="table-responsive">
                <table class="custom-table">
                    <thead>
                        <tr>
                            <th> </th>
                            <th>type</th>
                            <th>color</th>
                            <th>diameter</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>0</td>
                            <td>peanut butter</td>
                            <td>blue</td>
                            <td>16.20</td>
                        </tr>
                        <tr>
                            <td>1</td>
                            <td>peanut butter</td>
                            <td>brown</td>
                            <td>16.50</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>peanut butter</td>
                            <td>orange</td>
                            <td>15.48</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>peanut butter</td>
                            <td>brown</td>
                            <td>16.32</td>
                        </tr>
                        <tr>
                            <td>4</td>
                            <td>peanut butter</td>
                            <td>yellow</td>
                            <td>15.59</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <p>
                We can also look at the number of different values in one of the columns. Let's see how many different
                values we have in the "type" column:
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Count the values in the 'type' column
df['type'].value_counts()</code></pre>
            </div>
            <pre>plain            462
peanut butter    201
peanut           153
Name: type, dtype: int64</pre>
            <p>
                We see an excellent display of how many plain, peanut butter, and peanut M&M types are present in the
                DataFrame.
            </p>
            <h3>Challenge</h3>
            <p>
                Now, while using the M&Ms data set, practice loading and exploring the DataFrame; specifically, learn if
                there are any Null or NaN values in this data set and remove them if there are. You can also practice
                using the <code>df.sort_values()</code> method on one of the numeric columns ('mass' or 'diameter')
            </p>
            <h3>Additional Resources</h3>
            <ul>
                <li>
                    <a href="https://jakevdp.github.io/PythonDataScienceHandbook/" target="_blank"
                        rel="noopener noreferrer">
                        Python Data Science Handbook
                    </a>
                </li>
            </ul>
        </section>

        <section class="content-box">
            <h2>Objective 04 - Understand the Purpose of Feature Engineering</h2>
            <h3>Overview</h3>
            <p><strong>Why do we care about feature engineering?</strong></p>
            <p>
                When we begin working on a new project and a new data set, we have to consider how to make the best use
                of the information contained in the dataset. We want to get the most out of the data, without having to
                leave out useful information. It is also essential to ensure that the features we are using, are best
                suited for the type of modeling we would like to perform. In other words, what is the best
                representation of the data so that a model can learn from it? Choosing good features might allow you to
                use a less complex model, saving time on both implementation and interpretation.
            </p>
            <p>
                Many of these considerations fall under the process of "feature engineering." So before we dig too deep,
                let's take a closer look at what features are.
            </p>
            <h3>What are features?</h3>
            <p>
                A feature is a measurable property or attribute, and is often something that is measured or observed. It
                can be a numeric feature (eg. temperature, weight, time etc.), or categorical (eg: sex, color, group,
                etc. ). We usually work with data in the form of a table, also called tabular data. The data is composed
                of rows (also called observations, instances or samples) and columns (also called variables or
                attributes). Some of the columns in a data set contain features, such as a column measuring the
                temperature of something over time (measurable observation). But other columns, like the index, would
                not be considered a feature.
            </p>
            <h3>Feature importance and selection</h3>
            <p>
                Not all features are equal when it comes to using them in creating a model. Depending on the problem you
                are solving, some features may be more beneficial than others. Therefore, some criteria can rank
                features, and then the analysis can only use the top-ranked feature.
            </p>
            <h3>Feature extraction</h3>
            <p>
                Feature extraction doesn't exactly sound like a process you would apply to data, but it's an integral
                part of feature engineering. The process can be complex, but it's taking high-dimensional data and
                reducing it without taking away any information.Some standard methods of feature extraction include
                Principal Component Analysis (PCA) and unsupervised clustering methods.
            </p>
            <h3>Feature construction</h3>
            <p>
                The process of feature construction is a little more straightforward compared to feature extraction. By
                combining, splitting apart, or otherwise modifying existing features, you can create new features.For
                example, when using data that consists of a calendar date, we could break the date variable into years,
                months, and days. A new feature could then be given as the year or the month by itself.
            </p>
            <h3>Feature engineering process</h3>
            <p>
                Here we describe a basic feature engineering process. We will cover the individual steps of the process
                in more detail as the course progresses.
            </p>
            <ul>
                <li>Brainstorming or testing features</li>
                <li>Deciding what features to create</li>
                <li>Creating features</li>
                <li>Checking how the features work with your model</li>
                <li>Improving your features if needed</li>
                <li>Go back to brainstorming/creating more features until the work is complete</li>
            </ul>
            <h3>Follow Along</h3>
            <p>
                Now that we know what features are and some methods used to select, extract, and construct features, we
                will use another practice data set to create some new features from the existing columns. Next, we'll
                use the M&Ms data set to make some new features from what already exists in the data set.
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Import our libraries
import pandas as pd

# Read in the M&Ms data into a DataFrame
mms = pd.read_csv('https://tinyurl.com/mms-statistics')

# Display the data
display(mms.head())</code></pre>
            </div>
            <div class="table-responsive">
                <table class="custom-table">
                    <thead>
                        <tr>
                            <th> </th>
                            <th>type</th>
                            <th>color</th>
                            <th>diameter</th>
                            <th>mass</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>0</td>
                            <td>peanut butter</td>
                            <td>blue</td>
                            <td>16.20</td>
                            <td>2.18</td>
                        </tr>
                        <tr>
                            <td>1</td>
                            <td>peanut butter</td>
                            <td>brown</td>
                            <td>16.50</td>
                            <td>2.01</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>peanut butter</td>
                            <td>orange</td>
                            <td>15.48</td>
                            <td>1.78</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>peanut butter</td>
                            <td>brown</td>
                            <td>16.32</td>
                            <td>1.98</td>
                        </tr>
                        <tr>
                            <td>4</td>
                            <td>peanut butter</td>
                            <td>yellow</td>
                            <td>15.59</td>
                            <td>1.62</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <p>
                We don't have a lot of features to work with because this data set is small. But, we do have two
                physical measurements: diameter and mass. If you recall from your high-school science classes, we could
                use these two properties to create a new property: density.
            </p>
            <p>
                First, we'll assume that M&Ms candy is spherical. This equation determines the volume of a sphere:
                <code>V=(4/3) x pi x radius^3</code>. And then, the density is the mass divided by the volume. We need
                to create a new column (volume) and another column to hold the density values.
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Create the volume column (in cubic cm)

#divide the diameter by 10 to get cm
mms['diam_in_cm'] = mms['diameter']/10

#divide the diameter by 2 to get radius
#equation for spherical volume is 4/3 * pi * r^3
mms['volume'] = (4/3)*(3.14)*(mms['diam_in_cm']/2)**3

# Create the density column (in grams/cubic cm)
mms['density'] = mms['mass']/mms['volume']

# Take a look at the new columns
display(mms.head())</code></pre>
            </div>
            <div class="table-responsive">
                <table class="custom-table">
                    <thead>
                        <tr>
                            <th> </th>
                            <th>type</th>
                            <th>color</th>
                            <th>diameter</th>
                            <th>mass</th>
                            <th>diam_in_cm</th>
                            <th>volume</th>
                            <th>density</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>0</td>
                            <td>peanut butter</td>
                            <td>blue</td>
                            <td>16.20</td>
                            <td>2.18</td>
                            <td>1.620</td>
                            <td>2.224966</td>
                            <td>0.979790</td>
                        </tr>
                        <tr>
                            <td>1</td>
                            <td>peanut butter</td>
                            <td>brown</td>
                            <td>16.50</td>
                            <td>2.01</td>
                            <td>1.650</td>
                            <td>2.350879</td>
                            <td>0.854999</td>
                        </tr>
                        <tr>
                            <td>2</td>
                            <td>peanut butter</td>
                            <td>orange</td>
                            <td>15.48</td>
                            <td>1.78</td>
                            <td>1.548</td>
                            <td>1.941294</td>
                            <td>0.916914</td>
                        </tr>
                        <tr>
                            <td>3</td>
                            <td>peanut butter</td>
                            <td>brown</td>
                            <td>16.32</td>
                            <td>1.98</td>
                            <td>1.632</td>
                            <td>2.274777</td>
                            <td>0.870415</td>
                        </tr>
                        <tr>
                            <td>4</td>
                            <td>peanut butter</td>
                            <td>yellow</td>
                            <td>15.59</td>
                            <td>1.62</td>
                            <td>1.559</td>
                            <td>1.982973</td>
                            <td>0.816955</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <h3>Challenge</h3>
            <p>
                Now it's your turn: can you think of any additional features to create from the above data set? Try
                reading in this data and make some new columns, possibly using different units for the volume and
                density. The part to practice here is simply creating a new column; it doesn't matter if the property
                you create is applicable or not (for now).
            </p>
            <h3>Additional Resources</h3>
            <ul>
                <li>
                    <a href="https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/"
                        target="_blank" rel="noopener noreferrer">
                        Discover Feature Engineering
                    </a>
                </li>
            </ul>
        </section>

        <section class="content-box">
            <h2>Objective 05- Demonstrate How to Work With Strings in Pandas</h2>
            <h3>Overview</h3>
            <p>
                When we work with data, we're going to encounter many different data types: strings, integers, decimals,
                dates, times, null values, and possibly some other weird types not commonly found but that show up once
                in a while.
            </p>
            <h3>Text Data in Pandas</h3>
            <p>
                There are two ways to store text data in pandas: as an <code>object-dtype</code> NumPy array and as
                <code>StringDtype</code> extension type. <code>object</code> dtype is the default type we infer a list
                of strings to.
            </p>
            <p>
                For example, we can create a pandas Series with single characters and look at the dtype. It will show
                the default object dtype.
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Import pandas
import pandas as pd

# Create a Series with single characters
pd.Series(['a', 'b', 'c'])</code></pre>
                <pre><code class="language-python">0    a
1    b
2    c
dtype: object</code></pre>
            </div>
            <h3>String methods</h3>
            <p>
                There are many different string methods to format and clean up strings. Here are a few of the more
                common ways (they are generally similar to the built-in Python string methods):
            </p>
            <div class="table-responsive">
                <table class="table">
                    <thead>
                        <tr>
                            <th>method</th>
                            <th>description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>s.str.lower()</code></td>
                            <td>converts characters to lower case</td>
                        </tr>
                        <tr>
                            <td><code>s.str.upper()</code></td>
                            <td>converts characters to upper case</td>
                        </tr>
                        <tr>
                            <td><code>s.str.len()</code></td>
                            <td>returns the length of each item</td>
                        </tr>
                        <tr>
                            <td><code>s.str.strip()</code></td>
                            <td>removes white space</td>
                        </tr>
                        <tr>
                            <td><code>s.str.split('_')</code></td>
                            <td>separate on the given character</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <h3>Follow Along</h3>
            <p>
                Using another practice data set (yes, we like practice data sets), we will use some of the string
                methods to clean up the text data. To try out something different, we will use only a subset of UFO data
                set (the full data set is available here).
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Read in the locally saved sample data
ufo_df = pd.read_csv('scrubbed.csv')
ufo_df.head()</code></pre>
                <div class="table-responsive">
                    <table class="custom-table">
                        <thead>
                            <tr>
                                <th> </th>
                                <th>datetime</th>
                                <th>city</th>
                                <th>state</th>
                                <th>country</th>
                                <th>shape</th>
                                <th>duration (seconds)</th>
                                <th>comments</th>
                                <th>latitude</th>
                                <th>longitude</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>0</td>
                                <td>10/10/1970 16:00</td>
                                <td>bellmore</td>
                                <td>ny</td>
                                <td>us</td>
                                <td>disk</td>
                                <td>1800</td>
                                <td>silver disc seen by family and neighbors</td>
                                <td>40.668611</td>
                                <td>-73.527500</td>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>10/10/1971 21:00</td>
                                <td>lexington</td>
                                <td>nc</td>
                                <td>us</td>
                                <td>oval</td>
                                <td>30</td>
                                <td>green oval shaped light over my local church p...</td>
                                <td>35.823889</td>
                                <td>-80.253611</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>10/10/1974 23:00</td>
                                <td>hudson</td>
                                <td>ks</td>
                                <td>us</td>
                                <td>light</td>
                                <td>1200</td>
                                <td>The light chased us.</td>
                                <td>38.105556</td>
                                <td>-98.659722</td>
                            </tr>
                            <tr>
                                <td>3</td>
                                <td>10/10/1976 20:30</td>
                                <td>washougal</td>
                                <td>wa</td>
                                <td>us</td>
                                <td>oval</td>
                                <td>60</td>
                                <td>Three extremely large lights hanging above nea...</td>
                                <td>45.582778</td>
                                <td>-122.352222</td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>10/10/1980 23:30</td>
                                <td>manchester</td>
                                <td>nh</td>
                                <td>us</td>
                                <td>light</td>
                                <td>300</td>
                                <td>A red glowing sphere stopped and watched me.</td>
                                <td>42.995556</td>
                                <td>-71.455278</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

            </div>
            <p>
                It's also a good idea to get into the habit of looking at the data type in your DataFrame, which is easy
                using <code>ufo_df.info()</code>.
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Display the DataFrame 
ufo_df.info()</code></pre>
                <pre><code class="language-python">&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 11 entries, 0 to 10
Data columns (total 9 columns):
datetime              11 non-null object
city                  11 non-null object
state                 11 non-null object
country               11 non-null object
shape                 11 non-null object
duration (seconds)    11 non-null int64
comments              11 non-null object
latitude              11 non-null float64
longitude             11 non-null float64
dtypes: float64(2), int64(1), object(6)
memory usage: 920.0+ bytes</code></pre>
            </div>
            <h3>Text Cleaning</h3>
            <p>
                With the above information, we can see a mix of object-dtypes and numeric dtypes (int64, float64). In
                the <code>ufo_df</code> DataFrame, some text columns need some formatting help. Let's take the 'city,'
                'state,' and 'country' columns and format them as upper case.
            </p>
            <div class="code-example">
                <pre><code class="language-python"># Select each column (a column of a DataFrame is a Series)

# Convert the city names to title case (capitalize each work)
ufo_df['city'] = ufo_df['city'].str.title()

# Convert the state and country abbreviations to upper case
ufo_df['state'] = ufo_df['state'].str.upper()
ufo_df['country'] = ufo_df['country'].str.upper()

# Display the correct DataFrame
display(ufo_df.head())</code></pre>
                <div class="table-responsive">
                    <table class="custom-table">
                        <thead>
                            <tr>
                                <th> </th>
                                <th>datetime</th>
                                <th>city</th>
                                <th>state</th>
                                <th>country</th>
                                <th>shape</th>
                                <th>duration (seconds)</th>
                                <th>comments</th>
                                <th>latitude</th>
                                <th>longitude</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>0</td>
                                <td>10/10/1970 16:00</td>
                                <td>Bellmore</td>
                                <td>NY</td>
                                <td>US</td>
                                <td>disk</td>
                                <td>1800</td>
                                <td>silver disc seen by family and neighbors</td>
                                <td>40.668611</td>
                                <td>-73.527500</td>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>10/10/1971 21:00</td>
                                <td>Lexington</td>
                                <td>NC</td>
                                <td>US</td>
                                <td>oval</td>
                                <td>30</td>
                                <td>green oval shaped light over my local church p...</td>
                                <td>35.823889</td>
                                <td>-80.253611</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>10/10/1974 23:00</td>
                                <td>Hudson</td>
                                <td>KS</td>
                                <td>US</td>
                                <td>light</td>
                                <td>1200</td>
                                <td>The light chased us.</td>
                                <td>38.105556</td>
                                <td>-98.659722</td>
                            </tr>
                            <tr>
                                <td>3</td>
                                <td>10/10/1976 20:30</td>
                                <td>Washougal</td>
                                <td>WA</td>
                                <td>US</td>
                                <td>oval</td>
                                <td>60</td>
                                <td>Three extremely large lights hanging above nea...</td>
                                <td>45.582778</td>
                                <td>-122.352222</td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>10/10/1980 23:30</td>
                                <td>Manchester</td>
                                <td>NH</td>
                                <td>US</td>
                                <td>light</td>
                                <td>300</td>
                                <td>A red glowing sphere stopped and watched me.</td>
                                <td>42.995556</td>
                                <td>-71.455278</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
            <h3>Challenge</h3>
            <p>
                Clean up any additional columns using the complete UFO data set linked above (and in the Resources). You
                should download and look at the data first, either in a spreadsheet or in pandas. It's also an option to
                truncate or only use some of the rows to keep things a little more straightforward.
            </p>
            <h3>Additional Resources</h3>
            <ul>
                <li>
                    <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html" target="_blank"
                        rel="noopener noreferrer">
                        Working with text data
                    </a>
                </li>
                <li>
                    <a href="https://www.kaggle.com/NUFORC/ufo-sightings" target="_blank" rel="noopener noreferrer">
                        Kaggle: UFO Data set
                    </a>
                </li>
            </ul>
        </section>

        <section class="content-box">
            <h2>Guided Project</h2>
            <p>Open <strong>DS_112_EDA_Features.ipynb</strong> in the GitHub repository below to follow along with the
                guided project:</p>
            <div class="resource-links">
                <a href="https://github.com/bloominstituteoftechnology/DS-Unit-1-Sprint-1-Data-Wrangling-and-Storytelling/tree/master/module2-exploratory-data-analysis"
                    class="resource-link" target="_blank" rel="noopener noreferrer">GitHub: Module 2 Materials</a>
            </div>
            <h2>Guided Project Video</h2>
            <div class="video-container">
                <iframe class="wistia_embed" title="Sprint 1 Exploratory Data Analysis and Making Features Video"
                    src="https://fast.wistia.net/embed/iframe/v17o7mdtwo" width="640" height="360" allow="fullscreen"
                    loading="lazy"></iframe>
            </div>
        </section>

        <section class="content-box">
            <h2>Module Assignment</h2>
            <p>Complete the Module 2 assignment to practice exploratory data analysis and feature engineering techniques
                you've learned.</p>
            <div class="resource-links">
                <a href="https://github.com/bloominstituteoftechnology/DS-Unit-1-Sprint-1-Data-Wrangling-and-Storytelling/blob/master/module2-exploratory-data-analysis/DS_112_EDA_Features_Assignment_AG.ipynb"
                    class="resource-link" target="_blank" rel="noopener noreferrer">Module 2 Assignment</a>
            </div>

            <h2>Assignment Solution Video</h2>
            <div class="video-container">
                <iframe class="wistia_embed" title="Module 2 Assignment Solution"
                    src="https://fast.wistia.net/embed/iframe/ywi2wkg7sq" width="640" height="360" allow="fullscreen"
                    loading="lazy"></iframe>
            </div>
        </section>

        <section class="content-box">
            <h2>Resources</h2>
            <ul>
                <li><a href="https://github.com/bloominstituteoftechnology/DS-Unit-1-Sprint-1-Data-Wrangling-and-Storytelling/tree/master/module2-exploratory-data-analysis"
                        target="_blank" rel="noopener noreferrer">Module 2 GitHub Repository</a></li>
                <li><a href="https://pandas.pydata.org/docs/" target="_blank" rel="noopener noreferrer">Pandas
                        Documentation</a>
                </li>
                <li><a href="https://pandas.pydata.org/docs/user_guide/missing_data.html" target="_blank"
                        rel="noopener noreferrer">Pandas: Working with Missing Data</a></li>
                <li><a href="https://users.stat.ufl.edu/~winner/datasets.html" target="_blank"
                        rel="noopener noreferrer">UF
                        Statistics Datasets Collection</a></li>
            </ul>
        </section>
    </main>
</body>

</html>